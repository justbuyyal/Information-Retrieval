{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "other-env",
   "display_name": "Python (other-env)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IR HW5 Simple Mixture Model MAP@5000\n",
    "path = './ntust-ir-2020_hw5_new/'\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numba as nb\n",
    "from collections import Counter\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [02:38<00:00, 189.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# data of doc and query\n",
    "doc = []\n",
    "query = []\n",
    "# length of each doc\n",
    "doc_len = []\n",
    "# Name of doc and query\n",
    "doc_list = []\n",
    "query_list = []\n",
    "# TF of doc and query\n",
    "tf_doc = []\n",
    "tf_q = []\n",
    "# BM25 query vocabulary\n",
    "bm25_vocabulary = set()\n",
    "# Document IDF\n",
    "doc_idf = dict()\n",
    "# -----------------------------------------------------------------------------\n",
    "# get doc files and query files\n",
    "with open(path + 'query_list.txt', 'r') as fq:\n",
    "    line = fq.read().splitlines()\n",
    "    for l in line:\n",
    "        query_list.append(l)\n",
    "        f_temp = open(path + 'queries/{}.txt'.format(l))\n",
    "        temp_query = f_temp.read().split()\n",
    "        tf_q.append(Counter(temp_query))\n",
    "        for w in temp_query:\n",
    "            bm25_vocabulary.add(w)\n",
    "        query.append(temp_query)\n",
    "        f_temp.close()\n",
    "with open(path + 'doc_list.txt', 'r') as fd:\n",
    "    line = fd.read().splitlines()\n",
    "    for l in tqdm(line):\n",
    "        doc_list.append(l)\n",
    "        f_temp = open(path + 'docs/{}.txt'.format(l))\n",
    "        temp_doc = f_temp.read().split()\n",
    "        for k in Counter(temp_doc).keys():\n",
    "            if(k in doc_idf):\n",
    "                doc_idf[k] += 1\n",
    "            else: doc_idf[k] = 1\n",
    "        tf_doc.append(Counter(temp_doc))\n",
    "        doc.append(temp_doc)\n",
    "        doc_len.append(len(temp_doc))\n",
    "        f_temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BackGroud variable\n",
    "bg_len = np.sum(doc_len)\n",
    "# All doc, query and vocabulary length\n",
    "d_len = len(doc)\n",
    "q_len = len(query)\n",
    "# bm vocabulary to list\n",
    "bm25_vocabulary = list(bm25_vocabulary)\n",
    "bm25_len = len(bm25_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 324/324 [00:00<00:00, 328487.91it/s]31328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary\n",
    "vocabulary = set()\n",
    "for w in tqdm(bm25_vocabulary):\n",
    "    if(not(w in doc_idf)):\n",
    "        doc_idf[w] = 0\n",
    "        for d in range(d_len):\n",
    "            if(w in tf_doc[d]):\n",
    "                doc_idf[w] += 1\n",
    "for w in doc_idf.keys():\n",
    "    if(doc_idf[w] > 5):\n",
    "        vocabulary.add(w)\n",
    "vocabulary = list(vocabulary)\n",
    "w_len = len(vocabulary)\n",
    "print(w_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_counter = Counter(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query ULM\n",
    "q_ulm = []\n",
    "for q in range(q_len):\n",
    "    temp = dict()\n",
    "    ql = len(query[q])\n",
    "    for k,v in tf_q[q].items():\n",
    "        if(voc_counter[k] > 0):\n",
    "            temp[k] = v / ql\n",
    "    q_ulm.append(temp)\n",
    "# Doc ULM\n",
    "d_ulm = []\n",
    "for d in range(d_len):\n",
    "    temp = dict()\n",
    "    for k,v in tf_doc[d].items():\n",
    "        if(voc_counter[k] > 0):\n",
    "            temp[k] = v / doc_len[d]\n",
    "    d_ulm.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary index\n",
    "voc_index = dict()\n",
    "for w in range(w_len):\n",
    "    voc_index[vocabulary[w]] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 31328/31328 [08:09<00:00, 63.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Probability BackGround Model\n",
    "P_bg = np.zeros(w_len)\n",
    "for w in tqdm(range(w_len)):\n",
    "    s = 0\n",
    "    for d in range(d_len):\n",
    "        s += tf_doc[d][vocabulary[w]]\n",
    "    P_bg[w] = s / bg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF\n",
    "def IDF(idf, tf_key, bm25_voc, dl, bm25l):\n",
    "    for d in tqdm(range(dl)):\n",
    "        for v in range(bm25l):\n",
    "            if(tf_key[d][bm25_voc[v]] > 0):\n",
    "                idf[v] += 1\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 model variable\n",
    "K1 = 0.8\n",
    "b = 0.7\n",
    "N = d_len\n",
    "avg_dl = np.average(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [00:02<00:00, 14970.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# BM25 IDF\n",
    "idf_doc = np.zeros(len(bm25_vocabulary))\n",
    "idf_doc = IDF(idf_doc, tf_doc, bm25_vocabulary, d_len, bm25_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B25 Model\n",
    "def BM25(sim, k1, b_, N_, avg, dl_list, dl, ql, tf_key, Query, idf_, bm_voc):\n",
    "    for q in tqdm(range(ql)):\n",
    "        for d in range(dl):\n",
    "            sum = 0.0\n",
    "            for w in Query[q]:\n",
    "                w_tf = tf_key[d][w]\n",
    "                ni_loc = bm_voc.index(w)\n",
    "                ni = idf_[ni_loc]\n",
    "                sum_tmp = (k1 + 1) * w_tf / (k1 * ((1 - b) + b * dl_list[d] / avg) + w_tf)\n",
    "                sum_tmp *= log((N_ - ni + 0.5) / (ni + 0.5))\n",
    "                sum += sum_tmp\n",
    "            sim[q][d] = sum\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [00:46<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# BM25 Sim\n",
    "bm_sim = np.zeros([q_len, d_len], dtype=float)\n",
    "bm_sim = BM25(bm_sim, K1, b, N, avg_dl, doc_len, d_len, q_len, tf_doc, query, idf_doc, bm25_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMM variable\n",
    "SMM = int(5)\n",
    "Rq = np.zeros([q_len, SMM], dtype=np.int64)\n",
    "for q in range(q_len):\n",
    "    arg = np.argsort(-bm_sim[q])[:SMM]\n",
    "    for s in range(SMM):\n",
    "        Rq[q][s] = arg[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [00:05<00:00, 26.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Simple Mixture Model initialization\n",
    "PSMM = np.zeros([q_len, w_len])\n",
    "PTsmm = np.zeros([q_len, w_len])\n",
    "# Random\n",
    "for q in tqdm(range(q_len)):\n",
    "    r_sum = 0\n",
    "    for w in range(w_len):\n",
    "        p_temp = random.uniform(1.0, 10.0)\n",
    "        PSMM[q][w] = p_temp\n",
    "        r_sum += p_temp\n",
    "    for w in range(w_len):\n",
    "        PSMM[q][w] /= r_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMM E_step\n",
    "def E_step(tsmm, alpha_, psmm, p_bg):\n",
    "    mol = (1 - alpha_) * psmm\n",
    "    den = alpha_ * p_bg\n",
    "    den = np.sum(np.vstack((mol, den)), axis=0)\n",
    "    tsmm = np.divide(mol, den)\n",
    "    return tsmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Relevance c(w, d)\n",
    "def RC(r_w, rele_doc, rel_len, cq):\n",
    "    for d in range(rel_len):\n",
    "        for w in range(w_len):\n",
    "            r_w[d][w] = tf_doc[rele_doc[cq][d]][vocabulary[w]]\n",
    "    return r_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMM M_step\n",
    "def M_step(psmm, tsmm, r_w):\n",
    "    den = np.empty(w_len)\n",
    "    den.fill(np.sum(r_w))\n",
    "    mol = np.sum(r_w, axis=0)\n",
    "    mol = np.multiply(mol, tsmm)\n",
    "    psmm = np.divide(mol, den)\n",
    "    return psmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [09:34<00:00, 19.15s/it]\n"
     ]
    }
   ],
   "source": [
    "iter = 30\n",
    "alpha = 0.4\n",
    "for i in tqdm(range(iter)):\n",
    "    for q in range(q_len):\n",
    "        PTsmm[q] = E_step(PTsmm[q], alpha, PSMM[q], P_bg)\n",
    "        RC_array = np.zeros([SMM, w_len])\n",
    "        RC_array = RC(RC_array, Rq, SMM, q)\n",
    "        PSMM[q] = M_step(PSMM[q], PTsmm[q], RC_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL variable\n",
    "kl_alpha = 0.3\n",
    "kl_beta = 0.5\n",
    "kl_lamda = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_D(KL, alpha_, beta_, psmm, lamda):\n",
    "    for q in tqdm(range(q_len)):\n",
    "        ql = len(query[q])\n",
    "        p_w_q = np.zeros(w_len)\n",
    "        for k in tf_q[q].keys():\n",
    "            if(voc_counter[k] > 0):\n",
    "                p_w_q[voc_index[k]] = q_ulm[q][k] * alpha_\n",
    "        p_w_q = np.vstack((p_w_q, (beta_ * psmm[q])))\n",
    "        p_w_q = np.vstack((p_w_q, ((1 - alpha_ - beta_) * P_bg)))\n",
    "        p_w_q = np.sum(p_w_q, axis=0)\n",
    "        for d in range(d_len):\n",
    "            dl = doc_len[d]\n",
    "            p_w_d = np.zeros(w_len)\n",
    "            for k in tf_doc[d].keys():\n",
    "                if(voc_counter[k] > 0):\n",
    "                    p_w_d[voc_index[k]] = lamda * d_ulm[d][k]\n",
    "            p_w_d = np.log(np.sum(np.vstack((p_w_d, ((1 - lamda) * P_bg))), axis=0))\n",
    "            KL[q][d] = -np.sum(np.multiply(p_w_q, p_w_d))\n",
    "    return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [28:07<00:00, 11.25s/it]\n"
     ]
    }
   ],
   "source": [
    "kl_div = np.zeros([q_len, d_len])\n",
    "kl_div = KL_D(kl_div, kl_alpha, kl_beta, PSMM, kl_lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('KL.npy', kl_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output file\n",
    "fp = open(\"SMM.txt\", \"w\")\n",
    "fp.write(\"Query,RetrievedDocuments\\n\")\n",
    "for i in range(q_len):\n",
    "    fp.write('{},'.format(query_list[i]))\n",
    "    for s in np.argsort(kl_div[i])[:5000]:\n",
    "        fp.write(doc_list[s] + ' ')\n",
    "    fp.write('\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}