{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "other-env",
   "display_name": "Python (other-env)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IR HW5 Simple Mixture Model MAP@5000\n",
    "path = './ntust-ir-2020_hw5_new/'\n",
    "#path = '../HW2-BM25/ntust-ir-2020/'\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numba as nb\n",
    "from numba import njit\n",
    "from numba.core import types\n",
    "from numba.typed import List\n",
    "from collections import Counter\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [02:38<00:00, 189.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# data of doc and query(List of lists)\n",
    "query = List()\n",
    "doc = []\n",
    "# length of each doc\n",
    "doc_len = []\n",
    "# name of doc and query\n",
    "query_list = []\n",
    "doc_list = []\n",
    "# vocabulary\n",
    "vocabulary = set()\n",
    "# vocabulary counting(TF)\n",
    "TF = []\n",
    "# BackGround Counting\n",
    "bg_tf = Counter()\n",
    "# BM25 query vocabulary\n",
    "bm25_vocabulary = set()\n",
    "# get doc files and query files\n",
    "with open(path + 'query_list.txt', 'r') as fq:\n",
    "    line = fq.read().splitlines()\n",
    "    for l in line:\n",
    "        query_list.append(l)\n",
    "        f_temp = open(path + 'queries/{}.txt'.format(l))\n",
    "        temp_query = f_temp.read().split()\n",
    "        for v in temp_query:\n",
    "            bm25_vocabulary.add(v)\n",
    "            vocabulary.add(v)\n",
    "        query.append(List(temp_query))\n",
    "        f_temp.close()\n",
    "with open(path + 'doc_list.txt', 'r') as fd:\n",
    "    line = fd.read().splitlines()\n",
    "    for l in tqdm(line):\n",
    "        doc_list.append(l)\n",
    "        f_temp = open(path + 'docs/{}.txt'.format(l))\n",
    "        temp_doc = f_temp.read().split()\n",
    "        doc.append(temp_doc)\n",
    "        TF.append(Counter(temp_doc))\n",
    "        bg_tf.update(temp_doc)\n",
    "        doc_len.append(len(temp_doc))\n",
    "        for w in temp_doc:\n",
    "            vocabulary.add(w)\n",
    "        f_temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BackGroud variable\n",
    "bg_len = np.sum(doc_len)\n",
    "# All doc, query and vocabulary length\n",
    "d_len = len(doc)\n",
    "q_len = len(query)\n",
    "w_len = len(vocabulary)\n",
    "# vocabulary to list\n",
    "vocabulary = list(vocabulary)\n",
    "bm25_vocabulary =list(bm25_vocabulary)\n",
    "bm25_len = len(bm25_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [00:27<00:00, 1077.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build TF_key and TF_val\n",
    "TF_key = List()\n",
    "TF_val = List()\n",
    "for d in tqdm(range(d_len)):\n",
    "    TF_key.append(List([k for k in TF[d].keys()]))\n",
    "    TF_val.append(List([v for v in TF[d].values()]))\n",
    "# TF_k = List()\n",
    "# TF_v = List()\n",
    "# for d in range(d_len):\n",
    "#     TF_k.append(TF_key[d])\n",
    "#     TF_v.append(TF_val[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 154240/154240 [00:00<00:00, 908514.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Probability BackGround Model\n",
    "P_bg = np.zeros(w_len)\n",
    "for w in tqdm(range(w_len)):\n",
    "    P_bg[w] = bg_tf[vocabulary[w]] / bg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF\n",
    "@njit\n",
    "def IDF(idf, tf_key, bm25_voc, dl, bm25l):\n",
    "    for d in range(dl):\n",
    "        for v in range(bm25l):\n",
    "            if(bm25_voc[v] in tf_key[d]):\n",
    "                idf[v] += 1\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 model variable\n",
    "bm_sim = np.zeros([q_len, d_len], dtype=float) # 150 x 30000\n",
    "K1 = 0.8\n",
    "b = 0.7\n",
    "N = d_len\n",
    "avg_dl = np.average(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 1.22684 mins\n\n"
     ]
    }
   ],
   "source": [
    "# BM25 IDF\n",
    "idf_doc = np.zeros(len(bm25_vocabulary))\n",
    "time_idf = time.time()\n",
    "idf_doc = IDF(idf_doc, TF_key, bm25_vocabulary, d_len, bm25_len)\n",
    "print('time: {:.5f} mins\\n'.format((time.time() - time_idf) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B25 Model\n",
    "@njit\n",
    "def BM25(sim, k1, b_, N_, avg, dl_list, dl, ql, tf_key, tf_val, Query, idf_, bm_voc):\n",
    "    for q in range(ql):\n",
    "        for d in range(dl):\n",
    "            sum = 0.0\n",
    "            for w in Query[q]:\n",
    "                sum_tmp = 1.0\n",
    "                if(w in tf_key[d]):\n",
    "                    w_tf = tf_val[d][tf_key[d].index(w)]\n",
    "                    ni_loc = bm_voc.index(w)\n",
    "                    ni = idf_[ni_loc]\n",
    "                    sum_tmp = (k1 + 1) * w_tf / (k1 * ((1 - b) + b * dl_list[d] / avg) + w_tf)\n",
    "                    sum_tmp *= log((N_ - ni + 0.5) / (ni + 0.5))\n",
    "                sum += sum_tmp\n",
    "            sim[q][d] = sum\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 1.93 mins\n\n"
     ]
    }
   ],
   "source": [
    "time_bm = time.time()\n",
    "bm_sim = BM25(bm_sim, K1, b, N, avg_dl, doc_len, d_len, q_len, TF_key, TF_val, query, idf_doc, bm25_vocabulary)\n",
    "print('time: {:.2f} mins\\n'.format((time.time() - time_bm) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMM variable\n",
    "SMM_1 = int(500)\n",
    "Rq_1 = np.zeros([q_len, SMM_1], dtype=np.int64)\n",
    "for q in range(q_len):\n",
    "    arg = np.argsort(-bm_sim[q])[:SMM_1]\n",
    "    for s in range(SMM_1):\n",
    "        Rq_1[q][s] = arg[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [00:25<00:00,  5.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Simple Mixture Model initialization\n",
    "PSMM_temp = np.zeros([q_len, w_len])\n",
    "P_Tsmm_temp = np.zeros([q_len, w_len])\n",
    "# Random\n",
    "for q in tqdm(range(q_len)):\n",
    "    r_sum = 0\n",
    "    for w in range(w_len):\n",
    "        p_temp = random.uniform(1.0, 10.0)\n",
    "        PSMM_temp[q][w] = p_temp\n",
    "        r_sum += p_temp\n",
    "    for w in range(w_len):\n",
    "        PSMM_temp[q][w] /= r_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMM E_step\n",
    "@njit\n",
    "def E_step(tsmm, alpha_, psmm, p_bg, wl, ql):\n",
    "    for w in range(wl):\n",
    "        mol = (1 - alpha_) * psmm[w]\n",
    "        den = mol + alpha_ * p_bg[w]\n",
    "        tsmm[w] = mol / den\n",
    "    return tsmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance Doc matrix\n",
    "@njit\n",
    "def BRD(r_w, tf_key, tf_val, rel_len, wl, rel_doc, Vocabulary):\n",
    "    for r in range(rel_len):\n",
    "        t = rel_doc[r]\n",
    "        for w in range(wl):\n",
    "            if(Vocabulary[w] in tf_key[t]):\n",
    "                loc = tf_key[t].index(Vocabulary[w])\n",
    "                r_w[r][w] = tf_val[t][loc]\n",
    "    return r_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMM M_step\n",
    "@njit\n",
    "def M_step(psmm, r_w, Vocabulary, wl, ql, tsmm, tf_key, tf_val, rel_doc):\n",
    "    den = np.sum(np.dot(r_w, np.transpose(tsmm)))\n",
    "    for w in range(wl):\n",
    "        mol = 0.0\n",
    "        for d in rel_doc:\n",
    "            if(Vocabulary[w] in tf_key[d]):\n",
    "                mol += tf_val[d][tf_key[d].index(Vocabulary[w])] * tsmm[w]\n",
    "        psmm[w] = mol / den\n",
    "    return psmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nE_step_1:\n[0.92133031 0.02402542 0.87818925 ... 0.96266914 0.82527957 0.92974519]\nBRD:\n\n"
     ]
    }
   ],
   "source": [
    "iter = 30\n",
    "alpha = 0.7\n",
    "P_Tsmm_1 = np.copy(P_Tsmm_temp)\n",
    "PSMM_1 = np.copy(PSMM_temp)\n",
    "for q in range(q_len):\n",
    "    for i in range(iter):\n",
    "        print(\"\\nE_step_{}:\".format(i+1))\n",
    "        P_Tsmm_1[q] = E_step(P_Tsmm_1[q], alpha, PSMM_temp[q], P_bg, w_len, q_len)\n",
    "        print(P_Tsmm_1[q])\n",
    "        Rel_temp = np.zeros([SMM_1, w_len])\n",
    "        print(\"BRD:\\n\")\n",
    "        Rel_temp = BRD(Rel_temp, TF_key, TF_val, SMM_1, w_len, Rq_1[q], vocabulary)\n",
    "        print(\"\\nM_step_{}:\\n\".format(i+1))\n",
    "        time_smm = time.time()\n",
    "        PSMM_1[q] = M_step(PSMM_1[q], Rel_temp, vocabulary, w_len, q_len, P_Tsmm_1[q], TF_key, TF_val, Rq_1[q])\n",
    "        print(\"SMM out {}\\n\".format((time.time() - time_smm) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL Divergence\n",
    "kl_div = np.zeros([q_len, d_len], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL variable\n",
    "kl_alpha = 0.4\n",
    "kl_beta = 0.4\n",
    "kl_lamda = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def KL_D(KL, alpha_, beta_, psmm, dl, ql, wl, lamda, p_bg, Vocabulary):\n",
    "    for q in range(ql):\n",
    "        for d in range(dl):\n",
    "            sum = 0\n",
    "            for w in range(wl):\n",
    "                term_1 = alpha_ / wl\n",
    "                term_2 = beta_ * psmm[w]\n",
    "                term_3 = (1 - alpha_ - beta_) * p_bg[w]\n",
    "                term_4 = log(lamda * (Doc[d].count(Vocabulary[w]) / len(Doc[d])) + (1 - lamda) * p_bg[w])\n",
    "                sum += (term_1 + term_2 + term_3) * term_4\n",
    "            KL[q][d] = -sum\n",
    "    return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_kl = time.time()\n",
    "kl_div = KL_D(kl_div, kl_alpha, kl_beta, PSMM_1, d_len, q_len, w_len, kl_lamda, P_bg, vocabulary, doc)\n",
    "print('time: {:.2f} mins\\n'.format((time.time() - time_kl) / 60))"
   ]
  }
 ]
}