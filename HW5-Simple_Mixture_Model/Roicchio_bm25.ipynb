{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "other-env",
   "display_name": "Python (other-env)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './ntust-ir-2020_hw5_new/'\n",
    "# path = '../HW2-BM25/ntust-ir-2020/'\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "from collections import Counter\n",
    "from numba.typed import List\n",
    "from scipy import spatial\n",
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [02:55<00:00, 171.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# data of doc and query\n",
    "doc = []\n",
    "query = []\n",
    "# length of each doc\n",
    "doc_len = []\n",
    "# Name of doc and query\n",
    "doc_list = []\n",
    "query_list = []\n",
    "# TF of doc and query\n",
    "tf_doc = []\n",
    "tf_q = []\n",
    "# BM25 query vocabulary\n",
    "bm25_vocabulary = set()\n",
    "# Document IDF\n",
    "doc_idf = dict()\n",
    "# -----------------------------------------------------------------------------\n",
    "# get doc files and query files\n",
    "with open(path + 'query_list.txt', 'r') as fq:\n",
    "    line = fq.read().splitlines()\n",
    "    for l in line:\n",
    "        query_list.append(l)\n",
    "        f_temp = open(path + 'queries/{}.txt'.format(l))\n",
    "        temp_query = f_temp.read().split()\n",
    "        tf_q.append(Counter(temp_query))\n",
    "        for w in temp_query:\n",
    "            bm25_vocabulary.add(w)\n",
    "        query.append(temp_query)\n",
    "        f_temp.close()\n",
    "with open(path + 'doc_list.txt', 'r') as fd:\n",
    "    line = fd.read().splitlines()\n",
    "    for l in tqdm(line):\n",
    "        doc_list.append(l)\n",
    "        f_temp = open(path + 'docs/{}.txt'.format(l))\n",
    "        temp_doc = f_temp.read().split()\n",
    "        for k in Counter(temp_doc).keys():\n",
    "            if(k in doc_idf):\n",
    "                doc_idf[k] += 1\n",
    "            else: doc_idf[k] = 1\n",
    "        tf_doc.append(Counter(temp_doc))\n",
    "        doc.append(temp_doc)\n",
    "        doc_len.append(len(temp_doc))\n",
    "        f_temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsm vocabulary\n",
    "vsm_voc = set()\n",
    "bm25_vocabulary = list(bm25_vocabulary)\n",
    "# Doc, query and vocabulary length\n",
    "d_len = len(doc)\n",
    "q_len = len(query)\n",
    "bm_w_len = len(bm25_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [00:34<00:00, 873.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build TF_key and TF_val\n",
    "TF_doc_k = List()\n",
    "TF_doc_v = List()\n",
    "for d in tqdm(range(d_len)):\n",
    "    TF_doc_k.append(List([k for k in tf_doc[d].keys()]))\n",
    "    TF_doc_v.append(List([v for v in tf_doc[d].values()]))\n",
    "TF_q_k = List()\n",
    "TF_q_v = List()\n",
    "for q in range(q_len):\n",
    "    TF_q_k.append(List([k for k in tf_q[q].keys()]))\n",
    "    TF_q_v.append(List([v for v in tf_q[q].values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 324/324 [00:00<00:00, 325108.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for w in tqdm(bm25_vocabulary):\n",
    "    if(not(w in doc_idf)):\n",
    "        doc_idf[w] = 0\n",
    "        for d in range(d_len):\n",
    "            if(w in tf_doc[d]):\n",
    "                doc_idf[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "31328\n"
     ]
    }
   ],
   "source": [
    "# Build VSM vocabulary\n",
    "for w in doc_idf.keys():\n",
    "    if(doc_idf[w] > 5):\n",
    "        vsm_voc.add(w)\n",
    "vsm_voc = list(vsm_voc)\n",
    "w_len = len(vsm_voc)\n",
    "print(w_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 IDF\n",
    "@nb.njit\n",
    "def bm_IDF(idf, tf_key, bm25_voc, dl, bm25l):\n",
    "    for d in range(dl):\n",
    "        for v in range(bm25l):\n",
    "            if(bm25_voc[v] in tf_key[d]):\n",
    "                idf[v] += 1 \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 1.34534 mins\n\n"
     ]
    }
   ],
   "source": [
    "# BM25 IDF\n",
    "bm_idf = np.zeros(bm_w_len)\n",
    "time_idf = time.time()\n",
    "bm_idf = bm_IDF(bm_idf, TF_doc_k, bm25_vocabulary, d_len, bm_w_len)\n",
    "print('time: {:.5f} mins\\n'.format((time.time() - time_idf) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B25 Model\n",
    "@nb.njit\n",
    "def BM25(sim, k1, b_, N_, avg, dl_list, dl, ql, tf_key, tf_val, tf_q_key, idf_, bm_voc):\n",
    "    for q in range(ql):\n",
    "        for d in range(dl):\n",
    "            sum = 0.0\n",
    "            for w in tf_q_key[q]:\n",
    "                sum_tmp = 1.0\n",
    "                if(w in tf_key[d]):\n",
    "                    w_tf = tf_val[d][tf_key[d].index(w)]\n",
    "                    ni_loc = bm_voc.index(w)\n",
    "                    ni = idf_[ni_loc]\n",
    "                    sum_tmp = (k1 + 1) * w_tf / (k1 * ((1 - b) + b * dl_list[d] / avg) + w_tf)\n",
    "                    sum_tmp *= log((N_ - ni + 0.5) / (ni + 0.5))\n",
    "                sum += sum_tmp\n",
    "            sim[q][d] = sum\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 model variable\n",
    "bm_sim = np.zeros([q_len, d_len], dtype=float)\n",
    "K1 = 0.8\n",
    "b = 0.7\n",
    "N = d_len\n",
    "avg_dl = np.average(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 2.15 mins\n\n"
     ]
    }
   ],
   "source": [
    "time_bm = time.time()\n",
    "bm_sim = BM25(bm_sim, K1, b, N, avg_dl, doc_len, d_len, q_len, TF_doc_k, TF_doc_v, TF_q_k, bm_idf, bm25_vocabulary)\n",
    "print('time: {:.2f} mins\\n'.format((time.time() - time_bm) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output file\n",
    "fp = open(\"bm.txt\", \"w\")\n",
    "fp.write(\"Query,RetrievedDocuments\\n\")\n",
    "for i in range(q_len):\n",
    "    fp.write('{},'.format(query_list[i]))\n",
    "    for s in np.argsort(-bm_sim[i])[:5000]:\n",
    "        fp.write(doc_list[s] + ' ')\n",
    "    fp.write('\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "114\n117\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for w in range(w_len):\n",
    "    if(tf_doc[7][vsm_voc[w]] > 0):\n",
    "        c += 1\n",
    "print(c)\n",
    "print(len(tf_doc[7].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 31328/31328 [00:00<00:00, 661813.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build VSM Doc TF-IDF\n",
    "vsm_doc_idf = np.zeros(w_len, dtype=float)\n",
    "for w in tqdm(range(w_len)):\n",
    "    vsm_doc_idf[w] = log(1 + N / (doc_idf[vsm_voc[w]] + 1)) # log(1 + N / ni+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [11:25<00:00, 43.74it/s][[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF\n",
    "vsm_doc_tfidf = np.zeros([d_len, w_len], dtype=float)\n",
    "for d in tqdm(range(d_len)):\n",
    "    for w in range(w_len):\n",
    "        vsm_doc_tfidf[d][w] = 1 + tf_doc[d][vsm_voc[w]]\n",
    "print(vsm_doc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "57\n57\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for d in range(d_len):\n",
    "    if(tf_doc[d][vsm_voc[0]] > 0):\n",
    "        c += 1\n",
    "print(c)\n",
    "print(doc_idf[vsm_voc[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [00:01<00:00, 18668.47it/s][[6.25044112 6.84428286 6.84428286 ... 8.00670085 7.26512998 4.55124184]\n",
      " [6.25044112 6.84428286 6.84428286 ... 8.00670085 7.26512998 4.55124184]\n",
      " [6.25044112 6.84428286 6.84428286 ... 8.00670085 7.26512998 4.55124184]\n",
      " ...\n",
      " [6.25044112 6.84428286 6.84428286 ... 8.00670085 7.26512998 4.55124184]\n",
      " [6.25044112 6.84428286 6.84428286 ... 8.00670085 7.26512998 4.55124184]\n",
      " [6.25044112 6.84428286 6.84428286 ... 8.00670085 7.26512998 4.55124184]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "for d in tqdm(range(d_len)):\n",
    "    vsm_doc_tfidf[d] = np.multiply(vsm_doc_tfidf[d], vsm_doc_idf)\n",
    "print(vsm_doc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build VSM Query TF-IDF\n",
    "vsm_query_tfidf = np.zeros([q_len, w_len], dtype=float)\n",
    "# TF\n",
    "for q in range(q_len):\n",
    "    for w in range(w_len):\n",
    "        vsm_query_tfidf[q][w] = 0.5 + 0.5 * tf_q[q][vsm_voc[w]]\n",
    "# TF-IDF\n",
    "for q in range(q_len):\n",
    "    vsm_query_tfidf[q] = np.multiply(vsm_query_tfidf[q], vsm_doc_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[3.12522056, 3.42214143, 3.42214143, ..., 4.00335042, 3.63256499,\n",
       "        2.27562092],\n",
       "       [3.12522056, 3.42214143, 3.42214143, ..., 4.00335042, 3.63256499,\n",
       "        2.27562092],\n",
       "       [3.12522056, 3.42214143, 3.42214143, ..., 4.00335042, 3.63256499,\n",
       "        2.27562092],\n",
       "       ...,\n",
       "       [3.12522056, 3.42214143, 3.42214143, ..., 4.00335042, 3.63256499,\n",
       "        2.27562092],\n",
       "       [3.12522056, 3.42214143, 3.42214143, ..., 4.00335042, 3.63256499,\n",
       "        2.27562092],\n",
       "       [3.12522056, 3.42214143, 3.42214143, ..., 4.00335042, 3.63256499,\n",
       "        2.27562092]])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "vsm_query_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [07:46<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# Cos Sim\n",
    "old_cos_sim = np.zeros([q_len, d_len], dtype=float)\n",
    "for q in tqdm(range(q_len)):\n",
    "    for d in range(d_len):\n",
    "        old_cos_sim[q][d] = 1 - spatial.distance.cosine(vsm_query_tfidf[q], vsm_doc_tfidf[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.9993589 , 0.99419659, 0.99835489, ..., 0.99581334, 0.99950241,\n",
       "        0.99314931],\n",
       "       [0.99932916, 0.99416683, 0.99832676, ..., 0.99578356, 0.99947428,\n",
       "        0.99312121],\n",
       "       [0.99933224, 0.99417373, 0.99832985, ..., 0.99578188, 0.99947737,\n",
       "        0.9931243 ],\n",
       "       ...,\n",
       "       [0.9993577 , 0.9941954 , 0.99835531, ..., 0.99580736, 0.99950283,\n",
       "        0.99314973],\n",
       "       [0.99934464, 0.99418232, 0.99834224, ..., 0.99579428, 0.99948976,\n",
       "        0.99313668],\n",
       "       [0.99934924, 0.99424972, 0.99835949, ..., 0.99579889, 0.99949437,\n",
       "        0.99314128]])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "old_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output file\n",
    "fp = open(\"vsm.txt\", \"w\")\n",
    "fp.write(\"Query,RetrievedDocuments\\n\")\n",
    "for i in range(q_len):\n",
    "    fp.write('{},'.format(query_list[i]))\n",
    "    for s in np.argsort(-old_cos_sim[i])[:5000]:\n",
    "        fp.write(doc_list[s] + ' ')\n",
    "    fp.write('\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 1262.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get relevance document\n",
    "Rele_len = int(3)\n",
    "Rq = np.zeros([q_len, Rele_len], dtype=np.int64)\n",
    "for q in tqdm(range(q_len)):\n",
    "    arg = np.argsort(-bm_sim[q])[:Rele_len]\n",
    "    for r in range(Rele_len):\n",
    "        Rq[q][r] = arg[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Query\n",
    "def N_query(new_q, old_q, rel_doc, rel_len, doc_tfidf, ql, wl, alpha_, beta_, iter_):\n",
    "    for i in tqdm(range(iter_)):\n",
    "        for q in range(ql):\n",
    "                s1 = old_q[q] * alpha_\n",
    "                s2 = beta_ / rel_len\n",
    "                for d in range(rel_len):\n",
    "                    s1 = np.vstack((s1, (doc_tfidf[rel_doc[q][d]] * s2)))\n",
    "                new_q[q] = np.sum(s1, axis=0)\n",
    "        old_q = np.copy(new_q)\n",
    "    return new_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:07<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# new query model\n",
    "alpha = 1\n",
    "beta = 0.75\n",
    "iteration = 5\n",
    "new_query = np.zeros([q_len, w_len])\n",
    "new_query = N_query(new_query, vsm_query_tfidf, Rq, Rele_len, vsm_doc_tfidf, q_len, w_len, alpha, beta, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [12:13<00:00,  4.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# Cos Sim\n",
    "cos_sim = np.zeros([q_len, d_len], dtype=float)\n",
    "for q in tqdm(range(q_len)):\n",
    "    for d in range(d_len):\n",
    "        cos_sim[q][d] = 1 - spatial.distance.cosine(new_query[q], vsm_doc_tfidf[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.9994894 , 0.99565052, 0.99867143, ..., 0.99665996, 0.99959643,\n",
       "        0.99434325],\n",
       "       [0.99946428, 0.99562538, 0.99864689, ..., 0.99663391, 0.9995719 ,\n",
       "        0.99431874],\n",
       "       [0.99946698, 0.99563081, 0.9986496 , ..., 0.99663301, 0.99957461,\n",
       "        0.99432145],\n",
       "       ...,\n",
       "       [0.99948873, 0.99564985, 0.99867135, ..., 0.99665477, 0.99959635,\n",
       "        0.99434317],\n",
       "       [0.99947732, 0.99563844, 0.99865994, ..., 0.99664336, 0.99958495,\n",
       "        0.99433178],\n",
       "       [0.99948157, 0.99568883, 0.99867347, ..., 0.99664761, 0.99958919,\n",
       "        0.99433602]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output file\n",
    "fp = open(\"roicchio_{}_{}_iter_{}.txt\".format(alpha, beta, iteration), \"w\")\n",
    "fp.write(\"Query,RetrievedDocuments\\n\")\n",
    "for i in range(q_len):\n",
    "    fp.write('{},'.format(query_list[i]))\n",
    "    for s in np.argsort(-cos_sim[i])[:5000]:\n",
    "        fp.write(doc_list[s] + ' ')\n",
    "    fp.write('\\n')\n",
    "fp.close()"
   ]
  }
 ]
}