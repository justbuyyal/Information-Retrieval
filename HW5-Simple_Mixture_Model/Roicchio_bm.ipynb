{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "other-env",
   "display_name": "Python (other-env)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './ntust-ir-2020_hw5_new/'\n",
    "# path = '../HW2-BM25/ntust-ir-2020/'\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "from collections import Counter\n",
    "from numba.typed import List\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [00:06<00:00, 4385.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# data of doc and query\n",
    "doc = []\n",
    "query = []\n",
    "# length of each doc\n",
    "doc_len = []\n",
    "# Name of doc and query\n",
    "doc_list = []\n",
    "query_list = []\n",
    "# TF of doc and query\n",
    "tf_doc = []\n",
    "tf_q = []\n",
    "# BM25 query vocabulary\n",
    "bm25_vocabulary = set()\n",
    "# BackGround voc\n",
    "bg_counter = Counter()\n",
    "# -----------------------------------------------------------------------------\n",
    "# get doc files and query files\n",
    "with open(path + 'query_list.txt', 'r') as fq:\n",
    "    line = fq.read().splitlines()\n",
    "    for l in line:\n",
    "        query_list.append(l)\n",
    "        f_temp = open(path + 'queries/{}.txt'.format(l))\n",
    "        temp_query = f_temp.read().split()\n",
    "        tf_q.append(Counter(temp_query))\n",
    "        for w in temp_query: bm25_vocabulary.add(w)\n",
    "        query.append(temp_query)\n",
    "        f_temp.close()\n",
    "with open(path + 'doc_list.txt', 'r') as fd:\n",
    "    line = fd.read().splitlines()\n",
    "    for l in tqdm(line):\n",
    "        doc_list.append(l)\n",
    "        f_temp = open(path + 'docs/{}.txt'.format(l))\n",
    "        temp_doc = f_temp.read().split()\n",
    "        tf_doc.append(Counter(temp_doc))\n",
    "        bg_counter.update(temp_doc)\n",
    "        doc.append(temp_doc)\n",
    "        doc_len.append(len(temp_doc))\n",
    "        f_temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsm vocabulary\n",
    "vsm_voc = set()\n",
    "vsm_voc = bm25_vocabulary\n",
    "bm25_vocabulary = list(bm25_vocabulary)\n",
    "# All doc, query and vocabulary length\n",
    "d_len = len(doc)\n",
    "q_len = len(query)\n",
    "bm_w_len = len(bm25_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build VSM vocabulary\n",
    "for k,v in bg_counter.items():\n",
    "    if(v > 30): vsm_voc.add(k)\n",
    "vsm_voc = list(vsm_voc)\n",
    "w_len = len(vsm_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_len = sum(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16740"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "w_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BackGround Model\n",
    "P_bg = dict()\n",
    "for k,v in bg_counter.items():\n",
    "    P_bg[k] = v / bg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [00:29<00:00, 1032.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build TF_key and TF_val\n",
    "TF_doc_k = List()\n",
    "TF_doc_v = List()\n",
    "for d in tqdm(range(d_len)):\n",
    "    TF_doc_k.append(List([k for k in tf_doc[d].keys()]))\n",
    "    TF_doc_v.append(List([v for v in tf_doc[d].values()]))\n",
    "TF_q_k = List()\n",
    "TF_q_v = List()\n",
    "for q in range(q_len):\n",
    "    TF_q_k.append(List([k for k in tf_q[q].keys()]))\n",
    "    TF_q_v.append(List([v for v in tf_q[q].values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 IDF\n",
    "@nb.njit\n",
    "def bm_IDF(idf, tf_key, bm25_voc, dl, bm25l):\n",
    "    for d in range(dl):\n",
    "        for v in range(bm25l):\n",
    "            if(bm25_voc[v] in tf_key[d]):\n",
    "                idf[v] += 1 \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 1.27932 mins\n\n"
     ]
    }
   ],
   "source": [
    "# BM25 IDF\n",
    "bm_idf = np.zeros(bm_w_len)\n",
    "time_idf = time.time()\n",
    "bm_idf = bm_IDF(bm_idf, TF_doc_k, bm25_vocabulary, d_len, bm_w_len)\n",
    "print('time: {:.5f} mins\\n'.format((time.time() - time_idf) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B25 Model\n",
    "@nb.njit\n",
    "def BM25(sim, k1, b_, N_, avg, dl_list, dl, ql, tf_key, tf_val, tf_q_key, idf_, bm_voc):\n",
    "    for q in range(ql):\n",
    "        for d in range(dl):\n",
    "            sum = 0.0\n",
    "            for w in tf_q_key[q]:\n",
    "                sum_tmp = 1.0\n",
    "                if(w in tf_key[d]):\n",
    "                    w_tf = tf_val[d][tf_key[d].index(w)]\n",
    "                    ni_loc = bm_voc.index(w)\n",
    "                    ni = idf_[ni_loc]\n",
    "                    sum_tmp = (k1 + 1) * w_tf / (k1 * ((1 - b) + b * dl_list[d] / avg) + w_tf)\n",
    "                    sum_tmp *= log((N_ - ni + 0.5) / (ni + 0.5))\n",
    "                sum += sum_tmp\n",
    "            sim[q][d] = sum\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 model variable\n",
    "bm_sim = np.zeros([q_len, d_len], dtype=float)\n",
    "K1 = 0.8\n",
    "b = 0.7\n",
    "N = d_len\n",
    "avg_dl = np.average(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 1.90 mins\n\n"
     ]
    }
   ],
   "source": [
    "time_bm = time.time()\n",
    "bm_sim = BM25(bm_sim, K1, b, N, avg_dl, doc_len, d_len, q_len, TF_doc_k, TF_doc_v, TF_q_k, bm_idf, bm25_vocabulary)\n",
    "print('time: {:.2f} mins\\n'.format((time.time() - time_bm) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('bm.npy', bm_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSM IDF\n",
    "@nb.njit\n",
    "def IDF(idf, tf_key, voc, dl, wl):\n",
    "    for d in range(dl):\n",
    "        for v in range(wl):\n",
    "            if(voc[v] in tf_key[d]):\n",
    "                idf[v] += 1\n",
    "    for v in range(wl):\n",
    "        if(idf[v] != 0):\n",
    "            idf[v] = log(dl / idf[v])\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 65.89 mins\n\n"
     ]
    }
   ],
   "source": [
    "# Build VSM IDF\n",
    "vsm_doc_idf = np.zeros(w_len)\n",
    "vsm_d_time = time.time()\n",
    "vsm_doc_idf = IDF(vsm_doc_idf, TF_doc_k, vsm_voc, d_len, w_len)\n",
    "print('time: {:.2f} mins\\n'.format((time.time() - vsm_d_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('doc_idf.npy', vsm_doc_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def TF_IDF(tf_idf, idf, tf_d_k, tf_d_v, voc, dl, wl):\n",
    "    for w in range(wl):\n",
    "        idf_ = idf[w]\n",
    "        for d in range(dl):\n",
    "            if(voc[w] in tf_d_k[d]):\n",
    "                loc = tf_d_k[d].index(voc[w])\n",
    "                tf_idf[d][w] = idf_ * tf_d_v[d][loc]\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 91.86 mins\n\n"
     ]
    }
   ],
   "source": [
    "# Build VSM TF-IDF\n",
    "vsm_doc_tfidf = np.zeros([d_len, w_len])\n",
    "vsm_tfidf_time = time.time()\n",
    "vsm_doc_tfidf = TF_IDF(vsm_doc_tfidf, vsm_doc_idf, TF_doc_k, TF_doc_v, vsm_voc, d_len, w_len)\n",
    "print('time: {:.2f} mins\\n'.format((time.time() - vsm_tfidf_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('vsm.npy', vsm_doc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query TF-IDF\n",
    "@nb.njit\n",
    "def Q_TF_IDF(tf_idf, idf, tf_q_k, tf_q_v, voc, ql, wl):\n",
    "    for w in range(wl):\n",
    "        idf_ = idf[w]\n",
    "        for q in range(ql):\n",
    "            if(voc[w] in tf_q_k[q]):\n",
    "                loc = tf_q_k[q].index(voc[w])\n",
    "                tf_idf[q][w] = idf_ * (0.5 + 0.5 * tf_q_v[q][loc])\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Query TF-IDF\n",
    "vsm_query_tfidf = np.zeros([q_len, w_len])\n",
    "vsm_query_tfidf = Q_TF_IDF(vsm_query_tfidf, vsm_doc_idf, TF_q_k, TF_q_v, vsm_voc, q_len, w_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [05:02<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Cos Sim\n",
    "vsm_cos_sim = np.zeros([q_len, d_len], dtype=float)\n",
    "for q in tqdm(range(q_len)):\n",
    "    for d in range(d_len):\n",
    "        vsm_cos_sim[q][d] = 1 - spatial.distance.cosine(vsm_query_tfidf[q], vsm_doc_tfidf[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 1690.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get relevance document\n",
    "Rele_len = int(3)\n",
    "Rq = np.zeros([q_len, Rele_len], dtype=np.int64)\n",
    "for q in tqdm(range(q_len)):\n",
    "    arg = np.argsort(-bm_sim[q])[:Rele_len]\n",
    "    for r in range(Rele_len):\n",
    "        Rq[q][r] = arg[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Query\n",
    "def N_query(new_q, old_q, rel_doc, rel_len, doc_tfidf, ql, wl, alpha_, beta_, iter_):\n",
    "    for i in tqdm(range(iter_)):\n",
    "        for q in range(ql):\n",
    "                s1 = old_q[q] * alpha_\n",
    "                s2 = beta_ / rel_len\n",
    "                for d in range(rel_len):\n",
    "                    s1 = np.vstack((s1, np.array((doc_tfidf[rel_doc[q][d]] * s2))))\n",
    "                new_q[q] = np.sum(s1, axis=0)\n",
    "                for k in range(wl):\n",
    "                    if(new_q[q][k] < 0):\n",
    "                        new_q[q][k] = 0\n",
    "    return new_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# new query model\n",
    "alpha = 1\n",
    "beta = 0.75\n",
    "new_query = np.zeros([q_len, w_len])\n",
    "new_query = N_query(new_query, vsm_query_tfidf, Rq, Rele_len, vsm_doc_tfidf, q_len, w_len, alpha, beta, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 150/150 [05:05<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# Cos Sim\n",
    "cos_sim = np.zeros([q_len, d_len], dtype=float)\n",
    "for q in tqdm(range(q_len)):\n",
    "    for d in range(d_len):\n",
    "        cos_sim[q][d] = 1 - spatial.distance.cosine(new_query[q], vsm_doc_tfidf[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output file\n",
    "fp = open(\"roicchio_bm_{}_{}.txt\".format(alpha, beta), \"w\")\n",
    "fp.write(\"Query,RetrievedDocuments\\n\")\n",
    "for i in range(q_len):\n",
    "    fp.write('{},'.format(query_list[i]))\n",
    "    for s in np.argsort(-cos_sim[i])[:5000]:\n",
    "        fp.write(doc_list[s] + ' ')\n",
    "    fp.write('\\n')\n",
    "fp.close()"
   ]
  }
 ]
}